# Simple Agent Configuration

# Application Metadata
app:
  name: "Simple Agent"
  version: "0.1.0"

# Paths Configuration
paths:
  data_dir: "./data"
  logs_dir: "./logs"
  prompts: "./config/prompts"
  tools: "./config/tools"

# SSL Certificate Verification
# Set to false to disable SSL certificate verification (e.g., corporate proxies)
# Default: true
verify_certificates: false

# LLM Provider Settings
llm:
  # Active provider: openai, ollama, lmstudio, anthropic
  provider: "azure_openai"

  # Context window and token limits (shared across all providers)
  context_window: 128000  # Max tokens the model can handle
  max_input_tokens: 25000  # Hard limit for input prompt size to protect against rate limits

  # OpenAI Configuration
  openai:
    model: "gpt-4o-mini"
    api_key: "${OPENAI_API_KEY}"  # References .env
    temperature: 0.7
    max_tokens: 5000  # Max output tokens per request

  # LM Studio Configuration (local, OpenAI-compatible API)
  lmstudio:
    model: "llama-3.2-1b-instruct"
    base_url: "http://localhost:1234/v1"
    temperature: 0.7
    max_tokens: 5000  # Max output tokens per request

  # Ollama Configuration (local)
  ollama:
    model: "llama3.2:1b"
    base_url: "http://localhost:11434"
    temperature: 0.7
    max_tokens: 5000  # Max output tokens per request

  # Anthropic Configuration
  anthropic:
    model: "claude-3-5-sonnet-20241022"
    api_key: "${ANTHROPIC_API_KEY}"  # References .env
    temperature: 0.7
    max_tokens: 5000  # Max output tokens per request

  # Azure OpenAI Configuration (Enterprise/WTW)
  azure_openai:
    model: "gpt-4o-mini"  # Azure deployment name (see docs/Azure_model_names_and_versions.md)
    azure_endpoint: "https://api.lab.ai.wtwco.com/"  # Azure OpenAI endpoint URL
    #api_version: "2024-02-01"  # API version (verified working with basic OpenAI SDK)
    api_version: "2024-10-21"
    temperature: 0
    max_tokens: 16383
    auth_type: "azure_ad"  # Authentication: "azure_ad" (recommended) or "api_key"
    # api_key: "${AZURE_OPENAI_API_KEY}"  # Only needed if auth_type="api_key"


# Agent Settings
agents:
  # Agent auto-loading from config/agents/ directory
  auto_load_from_directory: false  # If true, loads all .yaml files from config/agents/ on startup

  # Default agent configuration
  default:
    role: "You are a helpful AI assistant."
    verbosity: 1  # 0=quiet, 1=normal, 2=verbose
    max_steps: 10  # Max tool call iterations
    agent_type: "tool_calling"  # "tool_calling" (safe, default) or "code" (requires Docker)
    # executor_type: "docker"  # Only for agent_type="code": "docker", "e2b", "modal", "wasm"
    tools:
    - tavily_web_search
    # Token budget protection (prevents hitting rate limits)
    token_budget: 20000  # Hard limit on input prompt size for this agent
    token_warning_threshold: 18000  # Warning logged when approaching limit
  # Note: column_matcher agent is defined in config/agents/column_matcher.yaml
  # It will be auto-loaded if auto_load_from_directory is true

# Orchestration Settings (Multi-Agent Workflows)
orchestration:
  flows_dir: "config/flows"  # Directory containing YAML flow definitions

# Tool Configuration
tools:
  tavily_web_search:
    enabled: true
    api_key_env: "TAVILY_API_KEY"  # Environment variable name for API key
    description: "Search the web using Tavily API for current information"
    timeout: 10

  fetch_webpage_markdown:
    enabled: true
    description: "Fetch a webpage and convert content to markdown"
    timeout: 10

# Debug Settings
debug:
  enabled: false  # Controls SmolAgents verbosity (tool calls, prompts, reasoning)
  level: "info"   # off (minimal), info (normal), debug (verbose) - controls logging level
  # Future: display_mode (full/minimal), output_template

# Logging
logging:
  level: "INFO"
  file: "logs/app.log"
  console_enabled: false
